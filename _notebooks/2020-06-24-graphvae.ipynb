{
 "cells": [
  {
   "source": [
    "# Molecular graph generation with PyTorch and PyGeometric\n",
    "> We use [GraphVAE](https://arxiv.org/abs/1802.03480) for molecular generation with one shot generation of a probabilistic graph with predefined maximum size. \n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: false\n",
    "- author: Anirudh Jain\n",
    "- categories: [graph generation, pytorch, pygeometric, tutorial]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Requirements\n",
    "\n",
    "The following packages need to be installed:\n",
    "- rdkit\n",
    "- pytorch\n",
    "- torch_geometric\n",
    "- networkx"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "#Initial imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import tqdm\n",
    "from rdkit import Chem \n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch_geometric.data import Batch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "source": [
    "# Introduction\n",
    "\n",
    "We represent a molecule as graph $G = (\\mathcal{X, A})$ using PyGeometric framework. Each molecule is represented by a feature matrix $\\mathcal{X}$ and adjacency matrix $\\mathcal{A}$. We use QM9 dataset from [MoleculeNet:A Benchmark for Molecular Machine Learning](https://arxiv.org/abs/1703.00564) implemented in `torch_geometric.datasets.QM9`. PyGeometric relies on rdkit to process the SMILES string and convert them into graphs.\n",
    "\n",
    "We modify the data processing script in two ways:\n",
    "- We strip hydrogen atoms from the molecules to keep only the heavy atoms\n",
    "- We kekulize the molecules to convert aromatic rings to Kekule form\n",
    "\n",
    "The modified script can be found [here](https://gist.github.com/sponde25/7dfa5492c21c007cf1e60a02dced1334)\n",
    "\n",
    "After processing the dataset, we have a set of molecules with 4 heavy atoms (C, N, O, F) and 3 bond types (SINGLE, DOUBLE and TRIPLE) with maximum graph size of 9. \n",
    "\n",
    "The decoder outputs the graph as one-hot encoded vectors for atoms `[9 x 5]` and bonds `[9 x 4]`. The label 0 represents empty atom or edge.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for data pre-processing\n",
    "\n",
    "import torch_geometric\n",
    "from qm9_modified import QM9\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MAX ATOMS: 9\nMAX EDGE: 72\n"
    }
   ],
   "source": [
    "# Setting up variables for the dataset\n",
    "\n",
    "MAX_ATOM = 5 \n",
    "MAX_EDGE = 4 \n",
    "path = '/scratch/project_2002655/datasets/qm9_noH' # Change the path for your local directory structure\n",
    "dataset = QM9(path)\n",
    "\n",
    "# Store the max. graph size\n",
    "MAX_N = -1\n",
    "for data in dataset:\n",
    "    if MAX_N < data.x.shape[0]: MAX_N = data.x.shape[0]\n",
    "MAX_E = int(MAX_N * (MAX_N - 1))\n",
    "print('MAX ATOMS: {}'.format(MAX_N))    # Maximum number of atoms in a graph in the dataset\n",
    "print('MAX EDGE: {}'.format(MAX_E))     # Corresponding size of upper triangle adjacency matrix "
   ]
  },
  {
   "source": [
    "`torch_geometric` stores the graph as `torch_geometric.data.Data` and we generate the one-hot representation of the graph $G$ as described above. For each graph $G$, we create a vector $\\mathcal{X}$ as one-hot encoded for atom of dimension `[MAX_N x MAX_ATOM]` and vector bond of dimension `[MAX_E x MAX_EDGE]`.\n",
    "\n",
    "![](../images/graphvae/data_representation.png \"A visualization of the graph, atom and edge representations\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 0,  0,  1,  2,  3,  4,  5,  6,  7],\n        [ 0,  0,  8,  9, 10, 11, 12, 13, 14],\n        [ 0,  0,  0, 15, 16, 17, 18, 19, 20],\n        [ 0,  0,  0,  0, 21, 22, 23, 24, 25],\n        [ 0,  0,  0,  0,  0, 26, 27, 28, 29],\n        [ 0,  0,  0,  0,  0,  0, 30, 31, 32],\n        [ 0,  0,  0,  0,  0,  0,  0, 33, 34],\n        [ 0,  0,  0,  0,  0,  0,  0,  0, 35],\n        [ 0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
    }
   ],
   "source": [
    "# We create a matrix to map the index of the edge vector $\\mathcal{A}$ to the upper triangular adjacency matrix.\n",
    "\n",
    "index_array = torch.zeros([MAX_N, MAX_N], dtype=int)\n",
    "idx = 0\n",
    "for i in range(MAX_N):\n",
    "    for j in range(MAX_N):\n",
    "        if i < j:\n",
    "            index_array[i, j] = idx\n",
    "            idx+=1\n",
    "\n",
    "print(index_array)"
   ]
  },
  {
   "source": [
    "We process the `torch_geometric.dataset` to generate matrices $\\mathcal{X}$ and $\\mathcal{A}$ which act as the ground truth for our decoder. We will also setup utility functions to convert between the vector representation $(\\mathcal{X}, \\mathcal{A})$ and `torch_geometric.data` representation $\\mathcal{G}$. We use the following key for atoms and bonds:\n",
    "```\n",
    "    C: 1    SINGLE: 1\n",
    "    N: 2    DOUBLE: 2\n",
    "    O: 3    TRIPLE: 3\n",
    "    F: 4\n",
    "```\n",
    "`0` is the placeholder label for empty entry."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the labels with -1\n",
    "edge_labels = torch.ones(len(dataset), MAX_E) * -1\n",
    "atom_labels = torch.ones(len(dataset), MAX_N) * -1\n",
    "idx = 0\n",
    "for data in dataset:\n",
    "    edge_attr = data.edge_attr      # One hot encoded bond labels\n",
    "    edge_index = data.edge_index    # Bond indices as one hot adjacency list\n",
    "    upper_index = edge_index[0] < edge_index[1] # Bond indices as upper triangular adjacency matrix\n",
    "    _, edge_label = torch.max(edge_attr, dim=-1)# Bond labels from one hot vectors\n",
    "    x = data.x[:, 1:5]              # One hot encoded atom labels\n",
    "    _, atom_label = torch.max(x, dim=-1)        # Atom labels from one hot vectors\n",
    "    # Expand the label vectors to size [MAX_N x MAX_ATOM] and [MAX_E x MAX_EDGE]\n",
    "    atom_labels[idx][:len(atom_label)] = atom_label\n",
    "    a0 = edge_index[0,upper_index]\n",
    "    a1 = edge_index[1,upper_index]\n",
    "    up_idx = index_array[a0, a1]\n",
    "    edge_labels[idx][up_idx] = edge_label[upper_index].float()\n",
    "    idx += 1\n",
    "\n",
    "atom_labels += 1\n",
    "edge_labels += 1"
   ]
  },
  {
   "source": [
    "Now that we have the dataset represented as $(\\mathcal{X}, \\mathcal{A})$ let's plot some graphs to visually check if the molecules are as we expected. We use `rdkit` to plot the molecules which does a lot of having lifting for us. The function `graphToMol` takes in the vectors $(\\mathcal{X}, \\mathcal{A})$ and returns an object of type `rdkit.Mol`. We can also obtain visualizations for the graphs $\\mathcal{G}$ by using `torch_geometric.utils.convert.to_networkx` and then ploting the netowrkx graph. But `rdkit` plots the molecules in a canonical orientation and is built to minimize intramolecular clashes, i.e. to maximize the clarity of the drawing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "def get_index(index, index_array):\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            if i < j:\n",
    "                if(index_array[i, j] == index):\n",
    "                    return [i, j]\n",
    "\n",
    "def graphToMol(atom, edge):\n",
    "\n",
    "    possible_atoms = {\n",
    "        0: 'H',\n",
    "        1: 'C',\n",
    "        2: 'N',\n",
    "        3: 'O',\n",
    "        4: 'F'\n",
    "    }\n",
    "    possible_edges = {\n",
    "        1: Chem.rdchem.BondType.SINGLE, \n",
    "        2: Chem.rdchem.BondType.DOUBLE, \n",
    "        3: Chem.rdchem.BondType.TRIPLE\n",
    "    }\n",
    "    max_n = 9\n",
    "    \n",
    "    mol = Chem.RWMol()\n",
    "    rem_idxs = []\n",
    "    for a in atom:    \n",
    "        atom_symbol = possible_atoms[a.item()]\n",
    "        mol.AddAtom(Chem.Atom(atom_symbol))\n",
    "    for a in mol.GetAtoms():\n",
    "        if a.GetAtomicNum() == 1:\n",
    "            rem_idxs.append(a.GetIdx())\n",
    "    for i, e in enumerate(edge):\n",
    "        e = e.item()\n",
    "        if e != 0:\n",
    "            a0, a1 = get_index(i, index_array)\n",
    "            if a0 in rem_idxs or a1 in rem_idxs:\n",
    "                return None\n",
    "            bond_type = possible_edges[e]\n",
    "            mol.AddBond(a0, a1, order=bond_type)\n",
    "    rem_idxs.sort(reverse=True)\n",
    "    for i in rem_idxs:\n",
    "        mol.RemoveAtom(i)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x600 at 0x7F0BFB18C828>",
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# We pick 9 random molecules from QM9 dataset to plot\n",
    "mols = []\n",
    "for i in np.random.randint(0, 100, size=9):\n",
    "    mols.append(graphToMol(atom_labels[i], edge_labels[i]))\n",
    "Chem.Draw.IPythonConsole.ShowMols(mols)"
   ]
  },
  {
   "source": [
    "The final step is to create a custom dataset for PyTorch which combines the two representations $\\mathcal{G}$ and $(\\mathcal{X}, \\mathcal{A})$. The dataset returns a list containing the graph, atom label and edge label. We also define a `collate_fn` which creates mini batches for the data loader that we will need for training and testing our model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "# Utility function to combine the torch_geometric.data and torch.tensor into one mini batch\n",
    "def collate_fn(datas):\n",
    "    graphs, atoms, edges = [], [], []\n",
    "    for data in datas:\n",
    "        graph, atom, edge = data\n",
    "        graphs.append(graph)\n",
    "        atoms.append(atom)\n",
    "        edges.append(edge)\n",
    "    graphs = Batch.from_data_list(graphs)\n",
    "    atoms = torch.stack(atoms)\n",
    "    edges = torch.stack(edges)\n",
    "    return graphs, atoms, edges\n",
    "\n",
    "# Returns the dataloader with a given batch size\n",
    "def get_dataloader(dataset, batch_size=32, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "# Create the dataset from the QM9 dataset from PyGeometric and the label matrices\n",
    "class GraphTensorDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.graph_dataset = QM9('/scratch/project_2002655/datasets/qm9_noH')\n",
    "        self.atom_labels = torch.load('/scratch/project_2002655/drug_discovery/saved/atom_labels_noH.tensor')\n",
    "        self.edge_labels = torch.load('/scratch/project_2002655/drug_discovery/saved/edge_labels_noH.tensor')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graph_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        graphs = self.graph_dataset[idx]\n",
    "        atoms = self.atom_labels[idx]\n",
    "        edges = self.edge_labels[idx]\n",
    "\n",
    "        return graphs, atoms, edges\n",
    "    \n",
    "    # return the subset of data with the specified size\n",
    "    def get_splits(self, train_size, test_size, cv_size=None):\n",
    "        total_data = len(self.graph_dataset)\n",
    "        if cv_size is not None:\n",
    "            trainset, testset = random_split(self, [train_size+cv_size, total_data - train_size - cv_size])\n",
    "            trainset, cvset = random_split(trainset, [train_size, cv_size])\n",
    "            testset, _ = random_split(testset, [test_size, len(testset) - test_size])\n",
    "            self.trainset = trainset\n",
    "            self.cvset = cvset\n",
    "            self.testset = testset\n",
    "            return self.trainset, self.testset, self.cvset\n",
    "        else:\n",
    "            trainset, testset = random_split(self, [train_size, total_data - train_size])\n",
    "            testset, _ = random_split(testset, [test_size, len(testset) - test_size])\n",
    "            self.trainset = trainset\n",
    "            self.testset = testset\n",
    "            return self.trainset, self.testset\n"
   ]
  },
  {
   "source": [
    "Now we wrap up this section by creating the train and test loaders with a mini batch of size `32`. We train the model on a subset of 500 molecules and test the reconstruction on 10000 molecules. To monitor training we look at three metrics averaged over the minibatch:\n",
    "- cross-entropy loss over the atom and edge labels\n",
    "- Atom label accuracy\n",
    "- Edge label accuracy "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphTensorDataset()\n",
    "train_size = int(500)\n",
    "test_size = int(10000)\n",
    "torch.manual_seed(0) # We set the random seed before the random split so we can get the same subset for reproducibility \n",
    "trainset, testset = dataset.get_splits(train_size, test_size)\n",
    "trainloader = get_dataloader(trainset)\n",
    "testloader = get_dataloader(testset)"
   ]
  },
  {
   "source": [
    "# Model\n",
    "\n",
    "Our generative model is a VAE with an encoder $q_\\phi (\\textbf{z} | \\mathcal{G})$ and a decoder $p_\\theta (\\mathcal{X}, \\mathcal{A} | \\textbf{z})$ parameterized by $\\phi$ and $\\theta$ respectively. We place a prior over the latent vector $\\textbf{z} \\sim \\mathcal{N}(0, I)$ which act as a regularizer to our model. Our goal is to map the graph $\\mathcal{G}$ into the latent vector $\\textbf{z}$ and generate new graphs by using the decoder to map new latent vectors sampled from the prior.\n",
    "\n",
    "***Encoder***: For a graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ with upto N nodes, we aim to map the graph to a latent vector $\\textbf{z} \\in \\mathbb{R}^D$. We use graph convolution network(GCN) to learn graph level feature vector $h_{\\mathcal{G}}$. For each node $\\mathcal{v} \\in \\mathcal{V}$, GCN update the node level features as,\n",
    "\\begin{equation}\n",
    "    h_{\\mathcal{v}} = \\sum_{\\mathcal{u} \\in Nbd(\\mathcal{v}, \\mathcal{G})}\\Phi (W_l^T X_{\\mathcal{u}})\n",
    "\\end{equation}\n",
    "where $Nbd(\\mathcal{v}, \\mathcal{G})$ is the neighborhood of node $\\mathcal{v}$ in graph $\\mathcal{G}$, $W_l$ are the shared weights analogous to the kernel in convolution layer and $X_\\mathcal{u}$ is the feature vector of node $\\mathcal{u}$ with $\\Phi$ as the non-linearity.\n",
    "\n",
    "After 2 graph convolution layers, we create a graph level vector representation by taking the mean of all node feature vectors $h_{\\mathcal{v}}$.\n",
    "\\begin{equation}\n",
    "    h_{\\mathcal{G}} = 1 / |\\mathcal{V}| \\sum_{\\mathcal{v} \\in \\mathcal{V}} h_{\\mathcal{v}}\n",
    "\\end{equation}\n",
    "Now we use fully connected layers to learn the latent vector $\\textbf{z}$ with the inference model as,\n",
    "\\begin{equation}\n",
    "    q(\\textbf{z}|\\mathcal{G}) = \\mathcal{N}(\\textbf{z}|\\mu(h_{\\mathcal{G}}), \\sigma^2(h_{\\mathcal{G}}))\n",
    "\\end{equation}\n",
    "where $\\mu(h_{\\mathcal{G}})$ and $\\sigma^2(h_{\\mathcal{G}})$ are parameterized by neural networks to learn the latent space.\n",
    "\n",
    "![](../images/graphvae/encoder_arch.png \"Visualization of the encoder architecture\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "***Decoder***: The primary problem with graph generation is that order of nodes can be arbritary which makes comparing two graphs a combatorial problem. We sidestep this problem by framing the graph generation problem as multi class classification problem. Keeping in the spirit of a toy example, we consider two independent classification problems. \n",
    "\n",
    "We train a decoder to predict atom and edge label vectors $(\\mathcal{X}, \\mathcal{A})$ respectively. We can train the model by using the standard VAE loss,\n",
    "\\begin{equation}\n",
    "    \\mathcal{L} = \\alpha_{\\mathcal{a}} \\mathcal{L}_{\\mathcal{a}} + \\alpha_\\mathcal{e} \\mathcal{L}_{\\mathcal{e}} + \\alpha_{KL} KL[q(\\textbf{z}|\\mathcal{G}) | p(\\textbf{z})]\n",
    "\\end{equation}\n",
    "\n",
    "$\\mathcal{L}_{\\mathcal{a}}$ and $\\mathcal{L}_{\\mathcal{e}}$ are the cross entropy loss for multiclass vectors for atoms and edges respectively. This restricts the decoder to memorize the ordering for the atom labels and independently learn the edges based only on the latent vector $\\textbf{z}$. We set $\\alpha_\\mathcal{a} = 1/|\\mathcal{X}|$, $\\alpha_\\mathcal{e} = 1/|{\\mathcal{A}}|$ and $\\alpha_KL = 1/ 128$ so all three loses are on the same scale. $\\mathcal{X}$ is the number of atoms in a mini batch, $|\\mathcal{A}|$ is the number of edges in a mini batch and we set the dimension of the latent vector as $128$.\n",
    "\n",
    "We use a single sample from the latent distribution to train the VAE and 100 samples during testing.\n",
    "\n",
    "![](../images/graphvae/decoder_arch.png \"Visualization of the decoder architecture\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, GlobalAttention\n",
    "from torch_geometric.utils import add_self_loops \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,  max_n, max_atoms, max_edges, in_features):\n",
    "        super(VAE, self).__init__()\n",
    "        n_output = int(max_n * (max_n - 1) / 2)\n",
    "        self.n_output = n_output\n",
    "        self.max_n = max_n\n",
    "        self.max_atoms = max_atoms\n",
    "        self.max_edges = max_edges\n",
    "\n",
    "        self.gc1 = GCNConv(in_features, 32)\n",
    "        self.gc2 = GCNConv(32, 64)\n",
    "        self.gc1_bn = nn.BatchNorm1d(32)\n",
    "        self.gc2_bn = nn.BatchNorm1d(64)\n",
    "\n",
    "        attn1 = nn.Linear(64, 1)\n",
    "        attn2 = nn.Linear(64, 64)\n",
    "        self.graph_pool = GlobalAttention(attn1, attn2)\n",
    "\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.mu = nn.Linear(128, 128)\n",
    "        self.logv = nn.Linear(128, 128)\n",
    "\n",
    "        self.dec1 = nn.Linear(128, 128)\n",
    "        self.dec1_bn = nn.BatchNorm1d(128)\n",
    "        self.dec2 = nn.Linear(128, 256)\n",
    "        self.dec2_bn = nn.BatchNorm1d(256)\n",
    "        self.dec3 = nn.Linear(256, 512)\n",
    "        self.dec3_bn = nn.BatchNorm1d(512)\n",
    "\n",
    "        self.atoms = nn.Linear(512, max_atoms*max_n)\n",
    "        self.edges = nn.Linear(512, max_edges*n_output)\n",
    "\n",
    "    def encode(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_index, _ = add_self_loops(edge_index)\n",
    "\n",
    "        x = self.gc1(x, edge_index)\n",
    "        x = F.relu(self.gc1_bn(x))\n",
    "        x = self.gc2(x, edge_index)\n",
    "        x = F.relu(self.gc2_bn(x))\n",
    "        #x = self.graph_pool(x, batch)\n",
    "        #x = F.tanh(x)\n",
    "        x = torch_geometric.nn.global_add_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.fc1_bn(x))\n",
    "        return self.mu(x), self.logv(x)\n",
    "\n",
    "    def sample(self, mu, logv):\n",
    "        eps = torch.randn_like(logv).to(mu.device)\n",
    "        return mu + eps * torch.exp(logv)\n",
    "\n",
    "    def decode(self, sample):\n",
    "        x = self.dec1(sample)\n",
    "        x = F.relu(self.dec1_bn(x))\n",
    "        x = self.dec2(x)\n",
    "        x = F.relu(self.dec2_bn(x))\n",
    "        x = self.dec3(x)\n",
    "        x = F.relu(self.dec3_bn(x))\n",
    "        \n",
    "        atoms = self.atoms(x)\n",
    "        atoms = atoms.view(-1, self.max_n, self.max_atoms)\n",
    "        atoms = F.softmax(atoms, dim=-1)\n",
    "\n",
    "        edges = self.edges(x)\n",
    "        edges = edges.view(-1, self.n_output, self.max_edges)\n",
    "        edges = F.softmax(edges, dim=-1)\n",
    "        return atoms, edges\n",
    "\n",
    "    def forward(self, data, num_samples=1):\n",
    "        mu, logv = self.encode(data)\n",
    "        _atoms, _edges = [], []\n",
    "        for i in range(num_samples):\n",
    "            sample = self.sample(mu, logv)\n",
    "            atoms, edges = self.decode(sample)\n",
    "            _atoms.append(atoms)\n",
    "            _edges.append(edges)      \n",
    "        return mu, logv, _atoms, _edges"
   ]
  },
  {
   "source": [
    "Now that we have the dataloader and the model, we can setup utility functions `train` and `test` along with the metrics that we need to evaluate the model performance. We use multi class accuracy to monitor as an indicator for model performance.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# KL loss for the latent vector\n",
    "def get_vae_loss(mu, logv):\n",
    "    kl_loss = 0.5 * torch.sum(torch.exp(logv) + mu**2 - 1.0 - logv)\n",
    "    return kl_loss/128\n",
    "\n",
    "# Reconstruction loss for atom and edge vectors\n",
    "def get_recon_loss(atom_true, atom_prob, edge_true, edge_prob):\n",
    "    ashape = atom_prob.shape\n",
    "    num_atoms = (atom_true!=0).int().sum()\n",
    "    atom_prob = torch.log(atom_prob)\n",
    "    atom_loss = F.nll_loss(atom_prob.view(-1, ashape[-1]), \n",
    "                                atom_true.view(-1).long(), reduction='sum') / num_atoms\n",
    "    eshape = edge_prob.shape\n",
    "    edge_prob = torch.log(edge_prob)\n",
    "    num_edges = (edge_true!=0).int().sum()\n",
    "    edge_loss = F.nll_loss(edge_prob.view(-1, eshape[-1]), \n",
    "                                edge_true.view(-1).long(), reduction='sum') / num_edges\n",
    "    return atom_loss, edge_loss\n",
    "\n",
    "# Return the correct predictions for multi class label classification\n",
    "def get_accuracy(y_true, y_prob, threshold = 0.5):\n",
    "    if len(y_prob.shape) <=2:\n",
    "        y_pred = (y_prob >= threshold).int()\n",
    "    else:\n",
    "        _, y_pred = torch.max(y_prob, dim=-1)\n",
    "    index = y_true != 0\n",
    "    correct = y_true[index] == y_pred[index]\n",
    "    return correct.int().sum(), index.int().sum()\n",
    "\n",
    "# Class to run and store training statistics we can monitor for model performance\n",
    "class Experiment():\n",
    "    def __init__(self, model, optimizer, path = './saved/tmp/'):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.path = path\n",
    "\n",
    "        Path(path+'models/').mkdir(parents=True, exist_ok=True)\n",
    "        Path(path+'metrics/').mkdir(parents=True, exist_ok=True)\n",
    "        Path(path+'figs/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.trainLoss = []\n",
    "        self.trainAcc = []\n",
    "        self.trainAUC = []\n",
    "        self.trainLossBatch = []\n",
    "        self.trainAccBatch = []\n",
    "        self.betaBatch = []\n",
    "        self.testLoss = []\n",
    "        self.testAcc = []\n",
    "        self.testAUC = []\n",
    "        self.testLossBatch = []\n",
    "        self.testAccBatch = []\n",
    "\n",
    "    def train(self, dataloader, epoch, cyclic = False, device = 'cuda'):\n",
    "        self.model.train()\n",
    "        \n",
    "        total_data = len(dataloader.dataset)\n",
    "        total_batches = len(dataloader)\n",
    "        batch_idx = epoch * total_batches\n",
    "        if cyclic:\n",
    "            batches_cycle = int(total_batches / 3)\n",
    "            batches_half_cycle = int(batches_cycle / 2)\n",
    "            betas = np.ones(batches_cycle)\n",
    "            betas[:batches_half_cycle] = np.linspace(0, 1, num=batches_half_cycle)\n",
    "        atom_correct = atom_total = edge_correct = edge_total = 0.\n",
    "        atom_auc = edge_auc = 0.\n",
    "        kl_loss = atom_loss = edge_loss = 0.\n",
    "        beta = 1\n",
    "\n",
    "        for data in dataloader:\n",
    "            graph = data[0].to(device)\n",
    "            atom_true = data[1].to(device)\n",
    "            edge_true = data[2].to(device)\n",
    "            batch_size = atom_true.shape[0]\n",
    "\n",
    "            # Core Training\n",
    "            self.optimizer.zero_grad()\n",
    "            mu, logv, atom_probs, edge_probs = self.model(graph)\n",
    "            _kl_loss = get_vae_loss(mu, logv)\n",
    "            aloss = eloss = 0.\n",
    "            for atom_prob, edge_prob in zip(atom_probs, edge_probs):\n",
    "                _atom_loss, _edge_loss = get_recon_loss(atom_true, atom_prob, edge_true, edge_prob)\n",
    "                aloss += _atom_loss\n",
    "                eloss += _edge_loss\n",
    "            C = len(atom_probs)\n",
    "            _atom_loss = aloss / C\n",
    "            _edge_loss = eloss / C\n",
    "            _recon_loss = _atom_loss + _edge_loss\n",
    "            if cyclic:\n",
    "                beta_idx = batch_idx % batches_cycle\n",
    "                beta = betas[beta_idx]\n",
    "            loss = _kl_loss * beta + _recon_loss \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            batch_idx += 1\n",
    "\n",
    "            with torch.no_grad():\n",
    "                self.trainLossBatch.append([_kl_loss, _atom_loss, _edge_loss])\n",
    "                self.betaBatch.append(beta)\n",
    "\n",
    "                kl_loss += _kl_loss.item() * batch_size\n",
    "                atom_loss += _atom_loss.item() * batch_size\n",
    "                edge_loss += _edge_loss.item() * batch_size\n",
    "                _atom_correct = _edge_correct = _atom_auc = _edge_auc = 0.\n",
    "                C = len(atom_probs)\n",
    "                for atom_prob, edge_prob in zip(atom_probs, edge_probs):\n",
    "                    acorrect, _atom_total = get_accuracy(atom_true, atom_prob)\n",
    "                    ecorrect, _edge_total = get_accuracy(edge_true, edge_prob)\n",
    "                    aauc = get_multi_auc(atom_true.cpu(), atom_prob.cpu(), atom_prob.shape[-1]) * batch_size\n",
    "                    eauc = get_multi_auc(edge_true.cpu(), edge_prob.cpu(), edge_prob.shape[-1]) * batch_size\n",
    "                    _atom_correct += acorrect\n",
    "                    _edge_correct += ecorrect\n",
    "                    _atom_auc += aauc \n",
    "                    _edge_auc += eauc \n",
    "                atom_auc += _atom_auc.item() / C\n",
    "                edge_auc += _edge_auc.item() / C\n",
    "                atom_correct += _atom_correct.item() / C\n",
    "                atom_total += _atom_total.item() \n",
    "                edge_correct += _edge_correct.item() / C\n",
    "                edge_total += _edge_total.item()\n",
    "\n",
    "                self.trainAccBatch.append([_atom_correct/C/_atom_total, _edge_correct/C/_edge_total])\n",
    "        \n",
    "        self.trainLoss.append([kl_loss/total_data, atom_loss/total_data, edge_loss/total_data])\n",
    "        self.trainAcc.append([atom_correct/atom_total, edge_correct/edge_total])\n",
    "        self.trainAUC.append([atom_auc/total_data, edge_auc/total_data])\n",
    "\n",
    "    def test(self, dataloader, epoch, num_samples = 1, device = 'cuda'):\n",
    "        self.model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            kl_loss = 0.\n",
    "            atom_loss = 0.\n",
    "            edge_loss = 0.\n",
    "            total_data = len(dataloader.dataset)\n",
    "            total_batches = len(dataloader)\n",
    "            batch_idx = epoch * total_batches\n",
    "            atom_correct = atom_total = edge_correct = edge_total = 0.\n",
    "            atom_auc = edge_auc = 0.\n",
    "\n",
    "            for data in dataloader:\n",
    "                graph = data[0].to(device)\n",
    "                atom_true = data[1].to(device)\n",
    "                edge_true = data[2].to(device)\n",
    "                batch_size = atom_true.shape[0]\n",
    "\n",
    "                mu, logv, atom_probs, edge_probs = self.model(graph, num_samples)\n",
    "                _kl_loss = get_vae_loss(mu, logv)\n",
    "                aloss = eloss = 0.\n",
    "                for atom_prob, edge_prob in zip(atom_probs, edge_probs):\n",
    "                    _atom_loss, _edge_loss = get_recon_loss(atom_true, atom_prob, edge_true, edge_prob)\n",
    "                    aloss += _atom_loss\n",
    "                    eloss += _edge_loss\n",
    "                C = len(atom_probs)\n",
    "                _atom_loss = aloss / C\n",
    "                _edge_loss = eloss / C\n",
    "\n",
    "                kl_loss += _kl_loss.item() * batch_size\n",
    "                atom_loss += _atom_loss.item() * batch_size\n",
    "                edge_loss += _edge_loss.item() * batch_size\n",
    "                _atom_correct = _edge_correct = _atom_auc = _edge_auc = 0.\n",
    "                C = len(atom_probs)\n",
    "                for atom_prob, edge_prob in zip(atom_probs, edge_probs):\n",
    "                    acorrect, _atom_total = get_accuracy(atom_true, atom_prob)\n",
    "                    ecorrect, _edge_total = get_accuracy(edge_true, edge_prob)\n",
    "                    aauc = get_multi_auc(atom_true.cpu(), atom_prob.cpu(), atom_prob.shape[-1]) * batch_size\n",
    "                    eauc = get_multi_auc(edge_true.cpu(), edge_prob.cpu(), edge_prob.shape[-1]) * batch_size\n",
    "                    _atom_correct += acorrect\n",
    "                    _edge_correct += ecorrect\n",
    "                    _atom_auc += aauc \n",
    "                    _edge_auc += eauc\n",
    "                atom_auc += _atom_auc.item() / C\n",
    "                edge_auc += _edge_auc.item() / C\n",
    "                atom_correct += _atom_correct.item() / C\n",
    "                atom_total += _atom_total.item() \n",
    "                edge_correct += _edge_correct.item() / C\n",
    "                edge_total += _edge_total.item()\n",
    "\n",
    "                self.testLossBatch.append([_kl_loss, _atom_loss, _edge_loss])\n",
    "                self.testAccBatch.append([_atom_correct/_atom_total, _edge_correct/_edge_total])\n",
    "\n",
    "            self.testLoss.append([kl_loss/total_data, atom_loss/total_data, edge_loss/total_data])\n",
    "            self.testAcc.append([atom_correct/atom_total, edge_correct/edge_total])\n",
    "            self.testAUC.append([atom_auc/total_data, edge_auc/total_data])\n",
    "\n",
    "    def save_state(self, epoch):\n",
    "        metrics = {}\n",
    "        trainLoss = np.array(self.trainLoss)\n",
    "        trainAcc = np.array(self.trainAcc)\n",
    "        trainAUC = np.array(self.trainAUC)\n",
    "        testLoss = np.array(self.testLoss)\n",
    "        testAcc = np.array(self.testAcc)\n",
    "        testAUC = np.array(self.testAUC)\n",
    "\n",
    "        metrics['Train KL Loss'] = trainLoss[:, 0]\n",
    "        metrics['Train Atom Loss'] = trainLoss[:, 1]\n",
    "        metrics['Train Edge Loss'] = trainLoss[:, 2]\n",
    "\n",
    "        metrics['Train Atom Acc'] = trainAcc[:, 0]\n",
    "        metrics['Train Edge Acc'] = trainAcc[:, 1]\n",
    "\n",
    "        metrics['Train Atom AUC'] = trainAUC[:, 0]\n",
    "        metrics['Train Edge AUC'] = trainAUC[:, 1]\n",
    "\n",
    "        metrics['Test KL Loss'] = testLoss[:, 0]\n",
    "        metrics['Test Atom Loss'] = testLoss[:, 1]\n",
    "        metrics['Test Edge Loss'] = testLoss[:, 2]\n",
    "\n",
    "        metrics['Test Atom Acc'] = testAcc[:, 0]\n",
    "        metrics['Test Edge Acc'] = testAcc[:, 1]\n",
    "\n",
    "        metrics['Test Atom AUC'] = testAUC[:, 0]\n",
    "        metrics['Test Edge AUC'] = testAUC[:, 1]\n",
    "\n",
    "        torch.save(metrics, self.path + 'metrics/epoch_{}.metric'.format(epoch))\n",
    "\n",
    "        batch_metrics = {}\n",
    "        trainLossBatch = np.array(self.trainLossBatch)\n",
    "        trainAccBatch = np.array(self.trainAccBatch)\n",
    "        testLossBatch = np.array(self.testLossBatch)\n",
    "        testAccBatch = np.array(self.testAccBatch)\n",
    "\n",
    "        batch_metrics['Train KL Loss'] = trainLossBatch[:, 0]\n",
    "        batch_metrics['Train Atom Loss'] = trainLossBatch[:, 1]\n",
    "        batch_metrics['Train Edge Loss'] = trainLossBatch[:, 2]\n",
    "\n",
    "        batch_metrics['Train Atom Acc'] = trainAccBatch[:, 0]\n",
    "        batch_metrics['Train Edge Acc'] = trainAccBatch[:, 1]\n",
    "\n",
    "        batch_metrics['Test KL Loss'] = testLossBatch[:, 0]\n",
    "        batch_metrics['Test Atom Loss'] = testLossBatch[:, 1]\n",
    "        batch_metrics['Test Edge Loss'] = testLossBatch[:, 2]\n",
    "\n",
    "        batch_metrics['Test Atom Acc'] = testAccBatch[:, 0]\n",
    "        batch_metrics['Test Edge Acc'] = testAccBatch[:, 1]\n",
    "        \n",
    "        torch.save(batch_metrics, self.path + 'metrics/batches.metric')\n",
    "        \n",
    "        torch.save(self.model.state_dict(), self.path + 'models/gvae_{}.model'.format(epoch))"
   ]
  },
  {
   "source": [
    "We can use many tricks from the VAE literature to improve performance and obtain better results. [Cyclic Annealing Schedule](https://arxiv.org/abs/1903.10145) for VAE training has been show to significantly improve performance on autoregressive NLP tasks such as language modeling, dialog response generation etc. We can train the model using cyclic annealing schedule by setting the flag `cyclic=True`.\n",
    "\n",
    "We use the mean of 40 samples during testing to calculate the loss and accuracy on the test set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(MAX_N, MAX_ATOM, MAX_EDGE, 13)\n",
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "epochs = 100\n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "path = './saved/test/'\n",
    "experiment = Experiment(model, optimizer, path)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    experiment.train(trainloader, epoch, cyclic=False)\n",
    "    experiment.test(testloader, epoch, 40)\n",
    "    experiment.save_state(epoch)"
   ]
  },
  {
   "source": [
    "# Results\n",
    "\n",
    "We train the model on the dataset of 500 molecules and test on a dataset of 10,000 molecules for 100 epochs. The small size of the trainset leads to a large generalization gap and the model overfits on trainset with the atom and edge cross entropy loss decreasing but a flat test loss. The test atom classification accuracy converges at around 80% while the edge classification accuracy converges at around 75%. We only consider the labels with non-zero entry in the ground truth to calculate accuracy.\n",
    "\n",
    "![](../images/graphvae/train_test_curves.png \"The train and test curves for the graphVAE model\")\n",
    "\n",
    "Now we consider metrics to check the generative performance for molecules. We sample $n_s = 10,000$ latent vectors $\\textbf{z}$ from the prior $\\mathcal{N}(0, I)$ and use the trained decoder to generate new molecules. We use the following three metrics to test the quality of the learned latent space:\n",
    "- Validity:     Let list $|V|$ represent chemically valid molecules, validity is the ratio $|V|/n_s$\n",
    "- Uniqueness:   The set of chemically valid molecules $U = set(V)$, uniqueness is the ratio $|U|/|V|$\n",
    "- Novelty:      Novelty is the set of elements in $U$ not in the trainset $\\mathcal{D}_{train}$ defined as $1 - (U \\cap \\mathcal{D}_{train})/|U|$\n",
    "\n",
    "We obtain the following results from our trained model:\n",
    "\n",
    "\n",
    "| Validity | Uniqueness | Novelty| \n",
    "|----------|-----------|---------|\n",
    "|    62.33%|   76.40%  |  66.71% |\n",
    "\n",
    "Even the simple toy example can generate a substantial number of unique and novel valid molecules. This is without any graph matching in the loss function so the model can learn to predict nodes in arbritary order and is restricted by the order of nodes in the trainset. Also these results are obtained from a very small subset of data and is comparable to [GraphAF](https://arxiv.org/abs/2001.09382) without validity checks during training as they report validity of 67% in Table 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Conclusion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}